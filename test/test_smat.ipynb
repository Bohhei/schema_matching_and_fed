{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "668c85e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from valentine import valentine_match, valentine_metrics\n",
    "from valentine.algorithms import Coma, Cupid, DistributionBased\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad69c726",
   "metadata": {},
   "source": [
    "### TPC-DI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082e6980",
   "metadata": {},
   "source": [
    "представим в виде (поскольку нет описания датасетов и атрибутов): dataset name 1, dataset name 2, attribute 1, attribute 2, attribute_match (0 or 1), constraints and meta-information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c197093d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_name1 = 'prospect_horizontal_50_ec_av'\n",
    "data_name1 = all_data_name1+'_source'\n",
    "data_name2 = all_data_name1+'_target'\n",
    "df1 = pd.read_csv(r'C:\\Users\\shepe\\Downloads\\Valentine-datasets\\prospect\\Unionable\\{}\\{}'.format(all_data_name1,data_name1+'.csv'))\n",
    "df2 = pd.read_csv(r'C:\\Users\\shepe\\Downloads\\Valentine-datasets\\prospect\\Unionable\\{}\\{}'.format(all_data_name1,data_name2+'.csv'))\n",
    "\n",
    "with open(r'C:\\Users\\shepe\\Downloads\\Valentine-datasets\\prospect\\Unionable\\{}\\{}_mapping.json'.format(all_data_name1,all_data_name1), 'r') as f:\n",
    "    mapping = json.load(f)\n",
    "ground_t1 = []\n",
    "for i in mapping['matches']:\n",
    "    ground_t1.append((i['source_column'],i['target_column']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3530a976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AgencyID</th>\n",
       "      <th>LastName</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>MiddleInitial</th>\n",
       "      <th>Gender</th>\n",
       "      <th>AddressLine1</th>\n",
       "      <th>AddressLine2</th>\n",
       "      <th>PostalCode</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>...</th>\n",
       "      <th>Income</th>\n",
       "      <th>NumberCars</th>\n",
       "      <th>NumberChildren</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>Age</th>\n",
       "      <th>CreditRating</th>\n",
       "      <th>OwnOrRentFlag</th>\n",
       "      <th>Employer</th>\n",
       "      <th>NumberCreditCards</th>\n",
       "      <th>NetWorth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PEL0</td>\n",
       "      <td>PELLAND</td>\n",
       "      <td>Netti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>21847 olympia street</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T6b 1i1</td>\n",
       "      <td>Fairbanks</td>\n",
       "      <td>MA</td>\n",
       "      <td>...</td>\n",
       "      <td>368776.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>W</td>\n",
       "      <td>20.0</td>\n",
       "      <td>760.0</td>\n",
       "      <td>O</td>\n",
       "      <td>Brink's</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1058868.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LED1</td>\n",
       "      <td>LEDUC</td>\n",
       "      <td>TRUDY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>245 congress court</td>\n",
       "      <td>APT. 624</td>\n",
       "      <td>77281</td>\n",
       "      <td>Quebec</td>\n",
       "      <td>PA</td>\n",
       "      <td>...</td>\n",
       "      <td>177967.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U</td>\n",
       "      <td>3.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1988185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lat2</td>\n",
       "      <td>latif</td>\n",
       "      <td>ireland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6517 frailing west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91355</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>...</td>\n",
       "      <td>321772.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>566.0</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3673128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RUD3</td>\n",
       "      <td>RUDDICK</td>\n",
       "      <td>Misti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11449 blalock park</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36615</td>\n",
       "      <td>Salem</td>\n",
       "      <td>AR</td>\n",
       "      <td>...</td>\n",
       "      <td>25449.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>W</td>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>Air Products &amp; Chemicals</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2005895.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JAY4</td>\n",
       "      <td>JAYAMANNE</td>\n",
       "      <td>sarena</td>\n",
       "      <td>M</td>\n",
       "      <td>f</td>\n",
       "      <td>18354 dodd court</td>\n",
       "      <td>Apt. 619</td>\n",
       "      <td>t6a 1i3</td>\n",
       "      <td>Toledo</td>\n",
       "      <td>OR</td>\n",
       "      <td>...</td>\n",
       "      <td>166567.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>M</td>\n",
       "      <td>21.0</td>\n",
       "      <td>815.0</td>\n",
       "      <td>O</td>\n",
       "      <td>Oshkosh</td>\n",
       "      <td>4.0</td>\n",
       "      <td>624736.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11231</th>\n",
       "      <td>Luq11255</td>\n",
       "      <td>Luqwavkqptlr7a4mfe4ljxuvlrtbu</td>\n",
       "      <td>rqlwrqbacndgdsdalzypvu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>4ndofwdqdrunlytfwvrg6mwuayujkzatcwtmzndkdklxl</td>\n",
       "      <td>PX5EPsJXIfFkWUFSLQXQT3SfIRTVPNFW</td>\n",
       "      <td>4oafz</td>\n",
       "      <td>Beaumomt</td>\n",
       "      <td>LA</td>\n",
       "      <td>...</td>\n",
       "      <td>143549.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>M</td>\n",
       "      <td>166.0</td>\n",
       "      <td>795.0</td>\n",
       "      <td>O</td>\n",
       "      <td>AbLAC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3410412.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11232</th>\n",
       "      <td>Rgq11247</td>\n",
       "      <td>Rnqdvabnq</td>\n",
       "      <td>Vziqhemczksmjfnqrldgcliitgq</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>gxtaswortlwgiipindwzdmccjehkopxgkrnfujjgxbdyqd...</td>\n",
       "      <td>VYABDvBvII4DFIGFJU</td>\n",
       "      <td>Gjxyhdkgjpf</td>\n",
       "      <td>Hohston</td>\n",
       "      <td>NH</td>\n",
       "      <td>...</td>\n",
       "      <td>230648.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>M</td>\n",
       "      <td>60.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>O</td>\n",
       "      <td>IMSgealth</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3522691.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11233</th>\n",
       "      <td>cvtq1247</td>\n",
       "      <td>xvtqfsmr9nkw</td>\n",
       "      <td>zkcvgsgn0zopbsyvxohlawfcacsf</td>\n",
       "      <td>G</td>\n",
       "      <td>F</td>\n",
       "      <td>QmXMJCNSCJnVBXWBLzZXEYpMWORDLhNY5aOaYYZIUMCbEI...</td>\n",
       "      <td>TP5dAKPVWOINJFQVxH7AjIoJhsLPsJTQMFWVm3RHVSTFFI...</td>\n",
       "      <td>Vrbsklvlaa</td>\n",
       "      <td>Daloas</td>\n",
       "      <td>WY</td>\n",
       "      <td>...</td>\n",
       "      <td>255294.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>736.0</td>\n",
       "      <td>R</td>\n",
       "      <td>Ch3mtura</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11234</th>\n",
       "      <td>ajf11248</td>\n",
       "      <td>ajbmfvboopntzlowpiodhbemitke9s</td>\n",
       "      <td>Koddgovylcrxbglkdjccchzeex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>wjgewydbgwqdjbbclclwfzpuumklyuuddna3iavvuqxvjur</td>\n",
       "      <td>Fslqwnegoregjncju1fgubecchjvpwhtpxubbycz0bialp...</td>\n",
       "      <td>eqlhas</td>\n",
       "      <td>y3andRapids</td>\n",
       "      <td>Novxxcotia</td>\n",
       "      <td>...</td>\n",
       "      <td>294567.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>M</td>\n",
       "      <td>5.0</td>\n",
       "      <td>519.0</td>\n",
       "      <td>R</td>\n",
       "      <td>Dell</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2099966.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11235</th>\n",
       "      <td>xpgw1249</td>\n",
       "      <td>zpgnxfl</td>\n",
       "      <td>yvdxgd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NUWLWWUYeRbTLBWTy</td>\n",
       "      <td>IckdDOSUzGZGXHICRDTU3CYBJX</td>\n",
       "      <td>Jcpxsytgz</td>\n",
       "      <td>Puebll</td>\n",
       "      <td>ME</td>\n",
       "      <td>...</td>\n",
       "      <td>288433.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>539.0</td>\n",
       "      <td>R</td>\n",
       "      <td>MvMMirage</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3335977.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11236 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AgencyID                        LastName                     FirstName  \\\n",
       "0          PEL0                         PELLAND                         Netti   \n",
       "1          LED1                           LEDUC                         TRUDY   \n",
       "2          lat2                           latif                       ireland   \n",
       "3          RUD3                         RUDDICK                         Misti   \n",
       "4          JAY4                       JAYAMANNE                        sarena   \n",
       "...         ...                             ...                           ...   \n",
       "11231  Luq11255   Luqwavkqptlr7a4mfe4ljxuvlrtbu        rqlwrqbacndgdsdalzypvu   \n",
       "11232  Rgq11247                       Rnqdvabnq   Vziqhemczksmjfnqrldgcliitgq   \n",
       "11233  cvtq1247                    xvtqfsmr9nkw  zkcvgsgn0zopbsyvxohlawfcacsf   \n",
       "11234  ajf11248  ajbmfvboopntzlowpiodhbemitke9s    Koddgovylcrxbglkdjccchzeex   \n",
       "11235  xpgw1249                         zpgnxfl                        yvdxgd   \n",
       "\n",
       "      MiddleInitial Gender                                       AddressLine1  \\\n",
       "0               NaN      f                               21847 olympia street   \n",
       "1               NaN      F                                 245 congress court   \n",
       "2               NaN    NaN                                 6517 frailing west   \n",
       "3               NaN    NaN                                 11449 blalock park   \n",
       "4                 M      f                                   18354 dodd court   \n",
       "...             ...    ...                                                ...   \n",
       "11231           NaN      F      4ndofwdqdrunlytfwvrg6mwuayujkzatcwtmzndkdklxl   \n",
       "11232           NaN      m  gxtaswortlwgiipindwzdmccjehkopxgkrnfujjgxbdyqd...   \n",
       "11233             G      F  QmXMJCNSCJnVBXWBLzZXEYpMWORDLhNY5aOaYYZIUMCbEI...   \n",
       "11234           NaN      F    wjgewydbgwqdjbbclclwfzpuumklyuuddna3iavvuqxvjur   \n",
       "11235           NaN      f                                  NUWLWWUYeRbTLBWTy   \n",
       "\n",
       "                                            AddressLine2   PostalCode  \\\n",
       "0                                                    NaN      T6b 1i1   \n",
       "1                                               APT. 624        77281   \n",
       "2                                                    NaN        91355   \n",
       "3                                                    NaN        36615   \n",
       "4                                               Apt. 619      t6a 1i3   \n",
       "...                                                  ...          ...   \n",
       "11231                   PX5EPsJXIfFkWUFSLQXQT3SfIRTVPNFW        4oafz   \n",
       "11232                                 VYABDvBvII4DFIGFJU  Gjxyhdkgjpf   \n",
       "11233  TP5dAKPVWOINJFQVxH7AjIoJhsLPsJTQMFWVm3RHVSTFFI...   Vrbsklvlaa   \n",
       "11234  Fslqwnegoregjncju1fgubecchjvpwhtpxubbycz0bialp...       eqlhas   \n",
       "11235                         IckdDOSUzGZGXHICRDTU3CYBJX    Jcpxsytgz   \n",
       "\n",
       "              City       State  ...    Income NumberCars  NumberChildren  \\\n",
       "0        Fairbanks          MA  ...  368776.0        NaN             3.0   \n",
       "1           Quebec          PA  ...  177967.0        5.0             1.0   \n",
       "2        Henderson     Alberta  ...  321772.0        2.0             1.0   \n",
       "3            Salem          AR  ...   25449.0        2.0             1.0   \n",
       "4           Toledo          OR  ...  166567.0        0.0             3.0   \n",
       "...            ...         ...  ...       ...        ...             ...   \n",
       "11231     Beaumomt          LA  ...  143549.0        3.0             3.0   \n",
       "11232      Hohston          NH  ...  230648.0        1.0             2.0   \n",
       "11233       Daloas          WY  ...  255294.0        2.0             1.0   \n",
       "11234  y3andRapids  Novxxcotia  ...  294567.0        5.0             3.0   \n",
       "11235       Puebll          ME  ...  288433.0        4.0             3.0   \n",
       "\n",
       "       MaritalStatus    Age CreditRating  OwnOrRentFlag  \\\n",
       "0                  W   20.0        760.0              O   \n",
       "1                  U    3.0        555.0              U   \n",
       "2                  S    NaN        566.0              O   \n",
       "3                  W   77.0          NaN              O   \n",
       "4                  M   21.0        815.0              O   \n",
       "...              ...    ...          ...            ...   \n",
       "11231              M  166.0        795.0              O   \n",
       "11232              M   60.0        264.0              O   \n",
       "11233              S    NaN        736.0              R   \n",
       "11234              M    5.0        519.0              R   \n",
       "11235              U    NaN        539.0              R   \n",
       "\n",
       "                       Employer NumberCreditCards   NetWorth  \n",
       "0                       Brink's               NaN  1058868.0  \n",
       "1                           NaN               6.0  1988185.0  \n",
       "2                           NaN               6.0  3673128.0  \n",
       "3      Air Products & Chemicals               3.0  2005895.0  \n",
       "4                       Oshkosh               4.0   624736.0  \n",
       "...                         ...               ...        ...  \n",
       "11231                     AbLAC               NaN  3410412.0  \n",
       "11232                 IMSgealth               3.0  3522691.0  \n",
       "11233                  Ch3mtura               6.0        NaN  \n",
       "11234                      Dell               3.0  2099966.0  \n",
       "11235                 MvMMirage               2.0  3335977.0  \n",
       "\n",
       "[11236 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ede3b10",
   "metadata": {},
   "source": [
    "constraints and meta-information - вся доп инвормация об атрибутах, которая может помочь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6051ed8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_constraints(df_):\n",
    "    constr = []\n",
    "    for i in df_.columns:\n",
    "        nnans = df_[i].isnull().sum()/len(df_[i])\n",
    "        column = df_[i].dropna()\n",
    "        type_ = column.dtype\n",
    "        nunique = column.nunique()\n",
    "        if type_=='object':\n",
    "            max_len = column.apply(lambda x: len(x)).max()\n",
    "            min_len = column.apply(lambda x: len(x)).min()\n",
    "            average_len = column.apply(lambda x: len(x)).mean()\n",
    "            describe = [0,0,0,0,0,0,0,0]\n",
    "            t = 1\n",
    "        else:\n",
    "            max_len = 0\n",
    "            min_len = 0\n",
    "            average_len = 0\n",
    "            describe = list(column.describe().values)\n",
    "            t = 0\n",
    "        \n",
    "        constr.append([nnans,t,nunique,max_len,min_len,average_len]+describe)\n",
    "    return constr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f9c5c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(df1,df2,ground_t1, data_name1='',data_name2=''):\n",
    "    constr1 = get_constraints(df1)\n",
    "    constr2 = get_constraints(df2)\n",
    "    data = []\n",
    "    for attr1_ind in range(len(df1.columns)):\n",
    "        attr1 = df1.columns[attr1_ind]\n",
    "        constr1_ = constr1[attr1_ind]\n",
    "        match = (attr1,'')\n",
    "        for ground in ground_t1:\n",
    "            if attr1 == ground[0]:\n",
    "                match = ground\n",
    "        for attr2_ind in range(len(df2.columns)):\n",
    "            attr2 = df2.columns[attr2_ind]\n",
    "            constr2_ = constr2[attr2_ind]\n",
    "            if attr2==match[1]:\n",
    "                res=1\n",
    "            else:\n",
    "                res=0\n",
    "            data.append([data_name1, data_name2, attr1,attr2,res,constr1_+constr2_])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b6f741d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = get_data(df1,df2, ground_t1, data_name1=data_name1,data_name2=data_name2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1f0d47",
   "metadata": {},
   "source": [
    "вторая пара"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51ad5fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_name2 = 'prospect_horizontal_50_ac5_ev'\n",
    "data_name1 = all_data_name2+'_source'\n",
    "data_name2 = all_data_name2+'_target'\n",
    "df1 = pd.read_csv(r'C:\\Users\\shepe\\Downloads\\Valentine-datasets\\prospect\\Unionable\\{}\\{}'.format(all_data_name2,data_name1+'.csv'))\n",
    "df2 = pd.read_csv(r'C:\\Users\\shepe\\Downloads\\Valentine-datasets\\prospect\\Unionable\\{}\\{}'.format(all_data_name2,data_name2+'.csv'))\n",
    "\n",
    "with open(r'C:\\Users\\shepe\\Downloads\\Valentine-datasets\\prospect\\Unionable\\{}\\{}_mapping.json'.format(all_data_name2,all_data_name2), 'r') as f:\n",
    "    mapping = json.load(f)\n",
    "ground_t1 = []\n",
    "for i in mapping['matches']:\n",
    "    ground_t1.append((i['source_column'],i['target_column']))\n",
    "\n",
    "data2 = get_data(df1,df2,ground_t1, data_name1=data_name1,data_name2=data_name2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb4075ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset1_name</th>\n",
       "      <th>dataset2_name</th>\n",
       "      <th>attr1_name</th>\n",
       "      <th>attr2_name</th>\n",
       "      <th>attribute_match</th>\n",
       "      <th>constraints</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prospect_horizontal_50_ec_av_source</td>\n",
       "      <td>prospect_horizontal_50_ec_av_target</td>\n",
       "      <td>AgencyID</td>\n",
       "      <td>AgencyID</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 1, 11236, 8, 4, 7.0107689569241725, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prospect_horizontal_50_ec_av_source</td>\n",
       "      <td>prospect_horizontal_50_ec_av_target</td>\n",
       "      <td>AgencyID</td>\n",
       "      <td>LastName</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 1, 11236, 8, 4, 7.0107689569241725, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prospect_horizontal_50_ec_av_source</td>\n",
       "      <td>prospect_horizontal_50_ec_av_target</td>\n",
       "      <td>AgencyID</td>\n",
       "      <td>FirstName</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 1, 11236, 8, 4, 7.0107689569241725, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prospect_horizontal_50_ec_av_source</td>\n",
       "      <td>prospect_horizontal_50_ec_av_target</td>\n",
       "      <td>AgencyID</td>\n",
       "      <td>MiddleInitial</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 1, 11236, 8, 4, 7.0107689569241725, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>prospect_horizontal_50_ec_av_source</td>\n",
       "      <td>prospect_horizontal_50_ec_av_target</td>\n",
       "      <td>AgencyID</td>\n",
       "      <td>Gender</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 1, 11236, 8, 4, 7.0107689569241725, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>prospect_horizontal_50_ac5_ev_source</td>\n",
       "      <td>prospect_horizontal_50_ac5_ev_target</td>\n",
       "      <td>NetWorth</td>\n",
       "      <td>prospect_crdtrtng</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.05170879316482734, 0, 10640, 0, 0, 0, 10655...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>prospect_horizontal_50_ac5_ev_source</td>\n",
       "      <td>prospect_horizontal_50_ac5_ev_target</td>\n",
       "      <td>NetWorth</td>\n",
       "      <td>prospect_wnrrntflg</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.05170879316482734, 0, 10640, 0, 0, 0, 10655...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>prospect_horizontal_50_ac5_ev_source</td>\n",
       "      <td>prospect_horizontal_50_ac5_ev_target</td>\n",
       "      <td>NetWorth</td>\n",
       "      <td>prospect_mplr</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.05170879316482734, 0, 10640, 0, 0, 0, 10655...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>prospect_horizontal_50_ac5_ev_source</td>\n",
       "      <td>prospect_horizontal_50_ac5_ev_target</td>\n",
       "      <td>NetWorth</td>\n",
       "      <td>prospect_nmbrcrdtcrds</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.05170879316482734, 0, 10640, 0, 0, 0, 10655...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>prospect_horizontal_50_ac5_ev_source</td>\n",
       "      <td>prospect_horizontal_50_ac5_ev_target</td>\n",
       "      <td>NetWorth</td>\n",
       "      <td>prospect_ntwrth</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.05170879316482734, 0, 10640, 0, 0, 0, 10655...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>968 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            dataset1_name  \\\n",
       "0     prospect_horizontal_50_ec_av_source   \n",
       "1     prospect_horizontal_50_ec_av_source   \n",
       "2     prospect_horizontal_50_ec_av_source   \n",
       "3     prospect_horizontal_50_ec_av_source   \n",
       "4     prospect_horizontal_50_ec_av_source   \n",
       "..                                    ...   \n",
       "963  prospect_horizontal_50_ac5_ev_source   \n",
       "964  prospect_horizontal_50_ac5_ev_source   \n",
       "965  prospect_horizontal_50_ac5_ev_source   \n",
       "966  prospect_horizontal_50_ac5_ev_source   \n",
       "967  prospect_horizontal_50_ac5_ev_source   \n",
       "\n",
       "                            dataset2_name attr1_name             attr2_name  \\\n",
       "0     prospect_horizontal_50_ec_av_target   AgencyID               AgencyID   \n",
       "1     prospect_horizontal_50_ec_av_target   AgencyID               LastName   \n",
       "2     prospect_horizontal_50_ec_av_target   AgencyID              FirstName   \n",
       "3     prospect_horizontal_50_ec_av_target   AgencyID          MiddleInitial   \n",
       "4     prospect_horizontal_50_ec_av_target   AgencyID                 Gender   \n",
       "..                                    ...        ...                    ...   \n",
       "963  prospect_horizontal_50_ac5_ev_target   NetWorth      prospect_crdtrtng   \n",
       "964  prospect_horizontal_50_ac5_ev_target   NetWorth     prospect_wnrrntflg   \n",
       "965  prospect_horizontal_50_ac5_ev_target   NetWorth          prospect_mplr   \n",
       "966  prospect_horizontal_50_ac5_ev_target   NetWorth  prospect_nmbrcrdtcrds   \n",
       "967  prospect_horizontal_50_ac5_ev_target   NetWorth        prospect_ntwrth   \n",
       "\n",
       "     attribute_match                                        constraints  \n",
       "0                  1  [0.0, 1, 11236, 8, 4, 7.0107689569241725, 0, 0...  \n",
       "1                  0  [0.0, 1, 11236, 8, 4, 7.0107689569241725, 0, 0...  \n",
       "2                  0  [0.0, 1, 11236, 8, 4, 7.0107689569241725, 0, 0...  \n",
       "3                  0  [0.0, 1, 11236, 8, 4, 7.0107689569241725, 0, 0...  \n",
       "4                  0  [0.0, 1, 11236, 8, 4, 7.0107689569241725, 0, 0...  \n",
       "..               ...                                                ...  \n",
       "963                0  [0.05170879316482734, 0, 10640, 0, 0, 0, 10655...  \n",
       "964                0  [0.05170879316482734, 0, 10640, 0, 0, 0, 10655...  \n",
       "965                0  [0.05170879316482734, 0, 10640, 0, 0, 0, 10655...  \n",
       "966                0  [0.05170879316482734, 0, 10640, 0, 0, 0, 10655...  \n",
       "967                1  [0.05170879316482734, 0, 10640, 0, 0, 0, 10655...  \n",
       "\n",
       "[968 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data= pd.DataFrame(data1+data2,columns = ['dataset1_name','dataset2_name', 'attr1_name', 'attr2_name', 'attribute_match', 'constraints'] )\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bda496ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_data['constraints'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2401fc9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['attribute_match'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c4151d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.to_pickle('TPC-DI_1.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58fcaa7",
   "metadata": {},
   "source": [
    "### Обучим smat+ с доп информацией и без нее"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ac6b4a",
   "metadata": {},
   "source": [
    "python train_2.py --dataset tpc --model_name aoa_3 --valset_ratio 0.1\n",
    "\n",
    "best_model_path: state_dict_2/tpc/aoa_3_tpc_val_f1_0.9362\n",
    "\n",
    "python train_2.py --dataset tpc --model_name aoa_2 --valset_ratio 0.1\n",
    "\n",
    "best_model_path: state_dict_2/tpc/aoa_2_tpc_val_f1_0.9362"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64776037",
   "metadata": {},
   "source": [
    "### Загрузим модели и проверим на данных, которые модели не видели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dc5e632",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import strftime, localtime\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset,random_split,SubsetRandomSampler, ConcatDataset\n",
    "from torchview import draw_graph\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from data_utils_2 import build_tokenizer, build_embedding_matrix, Dataset\n",
    "\n",
    "from models import AOA, AOA_2, AOA_3, AOA_4 , AOA_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73e00385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading tokenizer: tpc_tokenizer.dat\n",
      "loading embedding_matrix: 300_tpc_embedding_matrix.dat\n"
     ]
    }
   ],
   "source": [
    "class opt(object):\n",
    "    def __init__(self):\n",
    "        self.max_seq_len = 240\n",
    "        self.dataset = 'tpc'\n",
    "        self.embed_dim = 300\n",
    "        self.hidden_dim = 300\n",
    "        self.class_dim = 2\n",
    "        self.constr_dim = 28\n",
    "opt = opt()\n",
    "fnames = ['./datasets/omap/TPC-DI_1.p']\n",
    "\n",
    "tokenizer = build_tokenizer(\n",
    "    fnames,\n",
    "    max_seq_len=opt.max_seq_len,\n",
    "    dat_fname='{0}_tokenizer.dat'.format(opt.dataset))\n",
    "embedding_matrix = build_embedding_matrix(\n",
    "    word2idx=tokenizer.word2idx,\n",
    "    embed_dim=opt.embed_dim,\n",
    "    dat_fname='{0}_{1}_embedding_matrix.dat'.format(str(opt.embed_dim), opt.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8f828b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AOA_3(\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (embed): Embedding(93, 300)\n",
       "  (ctx_lstm): DynamicLSTM(\n",
       "    (RNN): LSTM(300, 300, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (asp_lstm): DynamicLSTM(\n",
       "    (RNN): LSTM(300, 300, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (ctxR_lstm): DynamicLSTM(\n",
       "    (RNN): LSTM(300, 300, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (aspR_lstm): DynamicLSTM(\n",
       "    (RNN): LSTM(300, 300, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (lin1): Linear(in_features=1800, out_features=512, bias=True)\n",
       "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (lin2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (lin3): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (lin1_c): Linear(in_features=28, out_features=64, bias=True)\n",
       "  (bn1_c): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (lin2_c): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (lin3_c): Linear(in_features=64, out_features=2, bias=True)\n",
       "  (obtained): Linear(in_features=4, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1 = AOA_3(embedding_matrix ,opt)\n",
    "model_1.load_state_dict(state_dict = torch.load('state_dict_2/tpc/aoa_3_tpc_val_f1_0.9362'))\n",
    "model_1.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "886df751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AOA_2(\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (embed): Embedding(93, 300)\n",
       "  (ctx_lstm): DynamicLSTM(\n",
       "    (RNN): LSTM(300, 300, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (asp_lstm): DynamicLSTM(\n",
       "    (RNN): LSTM(300, 300, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (ctxR_lstm): DynamicLSTM(\n",
       "    (RNN): LSTM(300, 300, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (aspR_lstm): DynamicLSTM(\n",
       "    (RNN): LSTM(300, 300, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (lin1): Linear(in_features=1800, out_features=512, bias=True)\n",
       "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (lin2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (lin3): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2 = AOA_2(embedding_matrix ,opt)\n",
    "model_2.load_state_dict(state_dict = torch.load('state_dict_2/tpc/aoa_2_tpc_val_f1_0.9362'))\n",
    "model_2.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197db811",
   "metadata": {},
   "source": [
    "Загрузим тестовые данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc6af4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name1 = 'prospect_horizontal_50_ec_ev_source'\n",
    "data_name2 = 'prospect_horizontal_50_ec_ev_target'\n",
    "df1 = pd.read_csv(r'C:\\Users\\shepe\\Downloads\\Valentine-datasets\\prospect\\Unionable\\prospect_horizontal_50_ec_ev\\prospect_horizontal_50_ec_ev_source.csv')\n",
    "df2 = pd.read_csv(r'C:\\Users\\shepe\\Downloads\\Valentine-datasets\\prospect\\Unionable\\prospect_horizontal_50_ec_ev\\prospect_horizontal_50_ec_ev_target.csv')\n",
    "\n",
    "with open(r'C:\\Users\\shepe\\Downloads\\Valentine-datasets\\prospect\\Unionable\\prospect_horizontal_50_ec_ev\\prospect_horizontal_50_ec_ev_mapping.json', 'r') as f:\n",
    "    mapping = json.load(f)\n",
    "ground_t1 = []\n",
    "for i in mapping['matches']:\n",
    "    ground_t1.append((i['source_column'],i['target_column']))\n",
    "\n",
    "data_test1 = get_data(df1,df2,ground_t1, data_name1=data_name1,data_name2=data_name2)\n",
    "df_data_test1= pd.DataFrame(data_test1,columns = ['dataset1_name','dataset2_name', 'attr1_name', 'attr2_name', 'attribute_match', 'constraints'] )\n",
    "df_data_test1.to_pickle('test_1.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6100ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name3 = 'prospect_horizontal_50_ac1_ev_source'\n",
    "data_name4 = 'prospect_horizontal_50_ac1_ev_target'\n",
    "df3 = pd.read_csv(r'C:\\Users\\shepe\\Downloads\\Valentine-datasets\\prospect\\Unionable\\prospect_horizontal_50_ac1_ev\\prospect_horizontal_50_ac1_ev_source.csv')\n",
    "df4 = pd.read_csv(r'C:\\Users\\shepe\\Downloads\\Valentine-datasets\\prospect\\Unionable\\prospect_horizontal_50_ac1_ev\\prospect_horizontal_50_ac1_ev_target.csv')\n",
    "\n",
    "with open(r'C:\\Users\\shepe\\Downloads\\Valentine-datasets\\prospect\\Unionable\\prospect_horizontal_50_ac1_ev\\prospect_horizontal_50_ac1_ev_mapping.json', 'r') as f:\n",
    "    mapping = json.load(f)\n",
    "ground_t2 = []\n",
    "for i in mapping['matches']:\n",
    "    ground_t2.append((i['source_column'],i['target_column']))\n",
    "\n",
    "data_test2 = get_data(df3,df4,ground_t2, data_name1=data_name3,data_name2=data_name4)\n",
    "df_data_test2= pd.DataFrame(data_test2,columns = ['dataset1_name','dataset2_name', 'attr1_name', 'attr2_name', 'attribute_match', 'constraints'] )\n",
    "df_data_test2.to_pickle('test_2.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35aa5fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tpc\n",
      "Finished write data file\n"
     ]
    }
   ],
   "source": [
    "testset1 = Dataset('test_1.p', tokenizer,dat_fname='{0}_12_test.dat'.format(opt.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4654045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tpc\n",
      "Finished write data file\n"
     ]
    }
   ],
   "source": [
    "testset2 = Dataset('test_2.p', tokenizer,dat_fname='{0}_13_test.dat'.format(opt.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7e15834",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_loader1 = DataLoader(dataset=testset1, batch_size=len(testset1), shuffle=False)\n",
    "test_data_loader2 = DataLoader(dataset=testset2, batch_size=len(testset2), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0fdb2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _test_model(data_loader, m, inputs_cols, data_test):\n",
    "    with torch.no_grad():\n",
    "        for t_batch, t_sample_batched in enumerate(data_loader):\n",
    "            t_inputs = [t_sample_batched[col] for col in inputs_cols]\n",
    "            t_targets = t_sample_batched['class_n']\n",
    "            t_outputs = m(t_inputs)\n",
    "            res = []\n",
    "            for i in range(len(t_targets)):\n",
    "                if torch.argmax(t_outputs[i], -1)==1:\n",
    "                    res.append((data_test[i][2:4],t_outputs[i]))\n",
    "                    \n",
    "\n",
    "            n_correct = (torch.argmax(t_outputs, -1) == t_targets).sum().item()\n",
    "            n_total = len(t_outputs)\n",
    "\n",
    "    acc = n_correct / n_total\n",
    "    return acc, res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a23e1c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9917355371900827"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_cols_1 = ['text_raw_indices1', 'aspect_indices1','text_raw_indices2', 'aspect_indices2', 'constraints']\n",
    "res_1 = _test_model(test_data_loader1, model_1, input_cols_1, data_test1)\n",
    "res_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4b8bc4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.993801652892562"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_2 = _test_model(test_data_loader2, model_1, input_cols_1, data_test2)\n",
    "res_2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "109f21ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9958677685950413"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_3 = _test_model(test_data_loader1, model_2, input_cols_1, data_test1)\n",
    "res_3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a11dd93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9834710743801653"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_4 = _test_model(test_data_loader2, model_2, input_cols_1, data_test2)\n",
    "res_4[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f506f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _test_on_ground_truth(ground_tr, predicted):\n",
    "    answer = {}\n",
    "    \n",
    "    predicted_unique = {i[0][1]:0 for i in predicted}\n",
    "    \n",
    "    for truth in ground_tr:\n",
    "        chosen_pr=''\n",
    "        for pr in predicted:\n",
    "            if truth[0]==pr[0][0] and  predicted_unique[pr[0][1]]<1:\n",
    "                if type(answer.get(truth[0], 0)) ==int: \n",
    "                    answer[truth[0]] = (pr[0][1], pr[1])\n",
    "                    chosen_pr=pr[0][1]\n",
    "                else:\n",
    "                    prob_1 = nn.functional.softmax(answer[truth[0]][1], dim=0)\n",
    "                    prob_2 = nn.functional.softmax(pr[1], dim=0)\n",
    "                    if prob_1[1]<prob_2[1]:\n",
    "                        answer[truth[0]] = (pr[0][1], pr[1])\n",
    "                        chosen_pr=pr[0][1]\n",
    "        predicted_unique[chosen_pr]=predicted_unique.get(chosen_pr,0)+1\n",
    "    total_tr = 0\n",
    "    for i in ground_tr:\n",
    "        try:\n",
    "            if i == (i[0], answer[i[0]][0]):\n",
    "                total_tr+=1\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return total_tr/len(ground_tr), answer\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca989135",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc1 = _test_on_ground_truth(ground_t1, res_1[1])\n",
    "acc2 = _test_on_ground_truth(ground_t2, res_2[1])\n",
    "acc3 = _test_on_ground_truth(ground_t1, res_3[1])\n",
    "acc4 = _test_on_ground_truth(ground_t2, res_4[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ec11c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9090909090909091, 0.9090909090909091, 1.0, 0.7272727272727273)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc1[0],acc2[0],acc3[0],acc4[0] # AOA_3 data1, AOA_3 data2, AOA_2 data1, AOA_2 data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7937258e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9090909090909091,\n",
       " {'AgencyID': ('AgencyID', tensor([-1.5182,  1.2892])),\n",
       "  'LastName': ('LastName', tensor([-0.5781,  0.5512])),\n",
       "  'FirstName': ('FirstName', tensor([-1.1674,  1.0134])),\n",
       "  'MiddleInitial': ('MiddleInitial', tensor([-1.1680,  1.0006])),\n",
       "  'Gender': ('Gender', tensor([-1.4718,  1.2285])),\n",
       "  'AddressLine1': ('AddressLine2', tensor([-1.7490,  1.4741])),\n",
       "  'AddressLine2': ('AddressLine1', tensor([-1.2272,  1.0650])),\n",
       "  'PostalCode': ('PostalCode', tensor([-2.1963,  1.8275])),\n",
       "  'City': ('City', tensor([-1.9069,  1.5723])),\n",
       "  'State': ('State', tensor([-1.0223,  0.8825])),\n",
       "  'Country': ('Country', tensor([-2.0826,  1.7179])),\n",
       "  'Phone': ('Phone', tensor([-1.7757,  1.4942])),\n",
       "  'Income': ('Income', tensor([-1.4526,  1.2180])),\n",
       "  'NumberCars': ('NumberCars', tensor([-1.0707,  0.9685])),\n",
       "  'NumberChildren': ('NumberChildren', tensor([-1.4229,  1.2414])),\n",
       "  'MaritalStatus': ('MaritalStatus', tensor([-1.6027,  1.3469])),\n",
       "  'Age': ('Age', tensor([-2.1089,  1.7785])),\n",
       "  'CreditRating': ('CreditRating', tensor([-0.8066,  0.7525])),\n",
       "  'OwnOrRentFlag': ('OwnOrRentFlag', tensor([-1.4047,  1.1956])),\n",
       "  'Employer': ('Employer', tensor([-2.0871,  1.7163])),\n",
       "  'NumberCreditCards': ('NumberCreditCards', tensor([-0.3780,  0.4293])),\n",
       "  'NetWorth': ('NetWorth', tensor([-0.3216,  0.2626]))})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52467b7",
   "metadata": {},
   "source": [
    "AOA_3 спутала 'AddressLine1' и 'AddressLine2'. Остальное верно."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9071fe",
   "metadata": {},
   "source": [
    "Модель без constraints может сравнивать атрибуты нормально только с похожими названиями"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a8e29f",
   "metadata": {},
   "source": [
    "### Посмотрим результаты с использованием Coma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd023fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Coma(strategy=\"COMA_OPT\")\n",
    "matches_1 = valentine_match(df1, df2, matcher)#df1,df2,ground_t1\n",
    "matches_2 = valentine_match(df3, df4, matcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a0dfb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _test_on_ground_truth_valentine(ground_tr, predicted):\n",
    "    i=0\n",
    "    total_tr = 0\n",
    "    for it in predicted.items():\n",
    "        for gr in ground_tr:\n",
    "            if gr == (it[0][0][1], it[0][1][1]):\n",
    "                total_tr+=1\n",
    "        i+=1\n",
    "    return total_tr/len(ground_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f222c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(_test_on_ground_truth_valentine(ground_t1, matches_1))\n",
    "print(_test_on_ground_truth_valentine(ground_t2, matches_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f81c56c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(('table_1', 'NumberCreditCards'),\n",
       "  ('table_2', 'prospect_NumberCreditCards')): 0.686985,\n",
       " (('table_1', 'NumberChildren'),\n",
       "  ('table_2', 'prospect_NumberChildren')): 0.6681818,\n",
       " (('table_1', 'MiddleInitial'),\n",
       "  ('table_2', 'prospect_MiddleInitial')): 0.64880383,\n",
       " (('table_1', 'MaritalStatus'),\n",
       "  ('table_2', 'prospect_MaritalStatus')): 0.64880383,\n",
       " (('table_1', 'OwnOrRentFlag'),\n",
       "  ('table_2', 'prospect_OwnOrRentFlag')): 0.64880383,\n",
       " (('table_1', 'PostalCode'), ('table_2', 'prospect_PostalCode')): 0.63934183,\n",
       " (('table_1', 'AddressLine1'),\n",
       "  ('table_2', 'prospect_AddressLine1')): 0.63687885,\n",
       " (('table_1', 'AddressLine2'),\n",
       "  ('table_2', 'prospect_AddressLine2')): 0.63687885,\n",
       " (('table_1', 'CreditRating'),\n",
       "  ('table_2', 'prospect_CreditRating')): 0.63687885,\n",
       " (('table_1', 'NumberCars'), ('table_2', 'prospect_NumberCars')): 0.60903883,\n",
       " (('table_1', 'FirstName'), ('table_2', 'prospect_FirstName')): 0.5926403,\n",
       " (('table_1', 'AgencyID'), ('table_2', 'prospect_AgencyID')): 0.5741608,\n",
       " (('table_1', 'LastName'), ('table_2', 'prospect_LastName')): 0.5741608,\n",
       " (('table_1', 'Employer'), ('table_2', 'prospect_Employer')): 0.5741608,\n",
       " (('table_1', 'NetWorth'), ('table_2', 'prospect_NetWorth')): 0.5741608,\n",
       " (('table_1', 'Country'), ('table_2', 'prospect_Country')): 0.5531652,\n",
       " (('table_1', 'Phone'), ('table_2', 'prospect_Phone')): 0.5446384,\n",
       " (('table_1', 'Gender'), ('table_2', 'prospect_Gender')): 0.5290847,\n",
       " (('table_1', 'Income'), ('table_2', 'prospect_Income')): 0.5290847,\n",
       " (('table_1', 'State'), ('table_2', 'prospect_State')): 0.50116014,\n",
       " (('table_1', 'City'), ('table_2', 'prospect_City')): 0.46835452,\n",
       " (('table_1', 'Age'), ('table_2', 'prospect_Age')): 0.42920938}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61173af4",
   "metadata": {},
   "source": [
    "### Проверим на большем числе датасетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97a2f030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_and_ground(all_data_name1):\n",
    "    data_name1 = all_data_name1+'_source'\n",
    "    data_name2 = all_data_name1+'_target'\n",
    "    df1 = pd.read_csv(r'C:\\Users\\shepe\\Downloads\\Valentine-datasets\\prospect\\Unionable\\{}\\{}'.format(all_data_name1,data_name1+'.csv'))\n",
    "    df2 = pd.read_csv(r'C:\\Users\\shepe\\Downloads\\Valentine-datasets\\prospect\\Unionable\\{}\\{}'.format(all_data_name1,data_name2+'.csv'))\n",
    "\n",
    "    with open(r'C:\\Users\\shepe\\Downloads\\Valentine-datasets\\prospect\\Unionable\\{}\\{}_mapping.json'.format(all_data_name1,all_data_name1), 'r') as f:\n",
    "        mapping = json.load(f)\n",
    "    ground_t1 = []\n",
    "    for i in mapping['matches']:\n",
    "        ground_t1.append((i['source_column'],i['target_column']))\n",
    "    return [data_name1,data_name2,df1,df2,ground_t1]\n",
    "\n",
    "def test_dl_models(df_and_ground, model):\n",
    "    data_name1= df_and_ground[0]\n",
    "    data_name2= df_and_ground[1]\n",
    "    df1 = df_and_ground[2]\n",
    "    df2 = df_and_ground[3]\n",
    "    ground_t1 = df_and_ground[4]\n",
    "    \n",
    "    name = data_name1 +'_'+ data_name2\n",
    "    \n",
    "    data_test1 = get_data(df1,df2,ground_t1, data_name1=data_name1,data_name2=data_name2)\n",
    "    df_data_test1= pd.DataFrame(data_test1,columns = ['dataset1_name','dataset2_name', 'attr1_name', 'attr2_name', 'attribute_match', 'constraints'] )\n",
    "    df_data_test1.to_pickle('test_{}.p'.format(name))\n",
    "    \n",
    "    testset1 = Dataset('test_{}.p'.format(name), tokenizer,dat_fname='{0}_12_test.dat'.format(opt.dataset))\n",
    "    \n",
    "    test_data_loader1 = DataLoader(dataset=testset1, batch_size=len(testset1), shuffle=False)\n",
    "    \n",
    "    input_cols_1 = ['text_raw_indices1', 'aspect_indices1','text_raw_indices2', 'aspect_indices2', 'constraints']\n",
    "    \n",
    "    res = _test_model(test_data_loader1, model, input_cols_1, data_test1)\n",
    "    \n",
    "    acc = _test_on_ground_truth(ground_t1, res[1])\n",
    "        \n",
    "    return acc\n",
    "\n",
    "def test_valentine_models(df_and_ground, matcher):\n",
    "    data_name1= df_and_ground[0]\n",
    "    data_name2= df_and_ground[1]\n",
    "    df1 = df_and_ground[2]\n",
    "    df2 = df_and_ground[3]\n",
    "    ground_t = df_and_ground[4]\n",
    "    \n",
    "    matches = valentine_match(df1, df2, matcher)\n",
    "    return _test_on_ground_truth_valentine(ground_t, matches), matches\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e461549",
   "metadata": {},
   "source": [
    "названия папок с датасетами на которых обучались"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d4eae4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('prospect_horizontal_50_ec_av', 'prospect_horizontal_50_ac5_ev')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_name1, all_data_name2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647f0407",
   "metadata": {},
   "source": [
    "Прверим модели на всех данных кроме этих"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "27cca139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n"
     ]
    }
   ],
   "source": [
    "pth = r'C:\\Users\\shepe\\Downloads\\Valentine-datasets\\prospect\\Unionable'\n",
    "dirs = os.listdir(pth)\n",
    "\n",
    "model_1 = AOA_3(embedding_matrix ,opt)\n",
    "model_1.load_state_dict(state_dict = torch.load('state_dict_2/tpc/aoa_3_tpc_val_f1_0.9362'))\n",
    "model_1.eval()\n",
    "\n",
    "model_2 = AOA_2(embedding_matrix ,opt)\n",
    "model_2.load_state_dict(state_dict = torch.load('state_dict_2/tpc/aoa_2_tpc_val_f1_0.9362'))\n",
    "model_2.eval()\n",
    "\n",
    "model_3 = AOA_3(embedding_matrix ,opt)\n",
    "model_3.load_state_dict(state_dict = torch.load('state_dict_2/tpc/aoa_3_tpc_val_f1_1.0'))\n",
    "model_3.eval()\n",
    "\n",
    "model_4 = AOA_3(embedding_matrix ,opt)\n",
    "model_4.load_state_dict(state_dict = torch.load('state_dict_2/tpc/aoa_3_tpc_val_f1_0.9599'))\n",
    "model_4.eval()\n",
    "\n",
    "acc_models = {'AOA_3':[],'AOA_2':[],'COMA':[], 'AOA_3_cross':[], 'AOA_3_cross_2':[]}\n",
    "\n",
    "for dir_ in dirs:\n",
    "    matcher = Coma(strategy=\"COMA_OPT\")\n",
    "    if dir_ not in [all_data_name1, all_data_name2]:\n",
    "        data = get_data_and_ground(dir_)\n",
    "        \n",
    "        acc1 = test_dl_models(data, model_1)\n",
    "        acc2 = test_dl_models(data, model_2)\n",
    "        acc3 = test_valentine_models(data, matcher)\n",
    "        acc4 = test_dl_models(data, model_3)\n",
    "        acc5 = test_dl_models(data, model_4)\n",
    "        \n",
    "        acc_models['AOA_3'] = acc_models['AOA_3']+[acc1[0]]\n",
    "        acc_models['AOA_2'] = acc_models['AOA_2']+[acc2[0]]\n",
    "        acc_models['COMA'] = acc_models['COMA']+[acc3[0]]\n",
    "        acc_models['AOA_3_cross'] = acc_models['AOA_3_cross']+[acc4[0]]\n",
    "        acc_models['AOA_3_cross_2'] = acc_models['AOA_3_cross_2']+[acc5[0]]\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fe25ada2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5548128342245989"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_models['AOA_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff9baf73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5762032085561497"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_models['AOA_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f2047e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7754010695187166"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_models['COMA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "178cc789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7165775401069518"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_models['AOA_3_cross'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4393cfb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6564171122994653"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_models['AOA_3_cross_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "734037ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 1.0,\n",
       " 0.18181818181818182,\n",
       " 0.22727272727272727,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.18181818181818182,\n",
       " 0.18181818181818182,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.18181818181818182,\n",
       " 0.18181818181818182,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.22727272727272727,\n",
       " 0.18181818181818182,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.22727272727272727,\n",
       " 0.22727272727272727,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.13636363636363635,\n",
       " 0.22727272727272727,\n",
       " 1.0,\n",
       " 1.0]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_models['AOA_3_cross']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d0b657bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 1.0,\n",
       " 0.7727272727272727,\n",
       " 0.7727272727272727,\n",
       " 0.8636363636363636,\n",
       " 0.8636363636363636,\n",
       " 0.36363636363636365,\n",
       " 0.36363636363636365,\n",
       " 0.6363636363636364,\n",
       " 0.6363636363636364,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.7727272727272727,\n",
       " 0.8636363636363636,\n",
       " 0.8636363636363636,\n",
       " 0.8636363636363636,\n",
       " 0.3181818181818182,\n",
       " 0.4090909090909091,\n",
       " 0.6363636363636364,\n",
       " 0.6363636363636364,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.8636363636363636,\n",
       " 0.6818181818181818,\n",
       " 0.8636363636363636,\n",
       " 0.8636363636363636,\n",
       " 0.36363636363636365,\n",
       " 0.45454545454545453,\n",
       " 0.6363636363636364,\n",
       " 1.0]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_models['COMA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8066512c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "new_dirs=[]\n",
    "for dir_ in dirs:\n",
    "    if dir_ not in [all_data_name1, all_data_name2]:\n",
    "        new_dirs.append(dir_)\n",
    "\n",
    "for i in range(len(new_dirs)):\n",
    "    if new_dirs[i] in ['prospect_horizontal_50_ac1_ev', 'prospect_horizontal_50_ec_ev']:\n",
    "        print(acc_models['AOA_3_cross'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "098e8e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prospect_horizontal_0_ac1_av 1.0\n",
      "prospect_horizontal_0_ac1_ev 1.0\n",
      "prospect_horizontal_0_ac2_av 0.18181818181818182\n",
      "prospect_horizontal_0_ac2_ev 0.22727272727272727\n",
      "prospect_horizontal_0_ac3_av 1.0\n",
      "prospect_horizontal_0_ac3_ev 1.0\n",
      "prospect_horizontal_0_ac4_av 0.18181818181818182\n",
      "prospect_horizontal_0_ac4_ev 0.18181818181818182\n",
      "prospect_horizontal_0_ac5_av 1.0\n",
      "prospect_horizontal_0_ac5_ev 1.0\n",
      "prospect_horizontal_0_ec_av 1.0\n",
      "prospect_horizontal_0_ec_ev 1.0\n",
      "prospect_horizontal_100_ac1_av 1.0\n",
      "prospect_horizontal_100_ac1_ev 1.0\n",
      "prospect_horizontal_100_ac2_av 0.18181818181818182\n",
      "prospect_horizontal_100_ac2_ev 0.18181818181818182\n",
      "prospect_horizontal_100_ac3_av 1.0\n",
      "prospect_horizontal_100_ac3_ev 1.0\n",
      "prospect_horizontal_100_ac4_av 0.22727272727272727\n",
      "prospect_horizontal_100_ac4_ev 0.18181818181818182\n",
      "prospect_horizontal_100_ac5_av 1.0\n",
      "prospect_horizontal_100_ac5_ev 1.0\n",
      "prospect_horizontal_100_ec_av 1.0\n",
      "prospect_horizontal_100_ec_ev 1.0\n",
      "prospect_horizontal_50_ac1_av 1.0\n",
      "prospect_horizontal_50_ac1_ev 1.0\n",
      "prospect_horizontal_50_ac2_av 0.22727272727272727\n",
      "prospect_horizontal_50_ac2_ev 0.22727272727272727\n",
      "prospect_horizontal_50_ac3_av 1.0\n",
      "prospect_horizontal_50_ac3_ev 1.0\n",
      "prospect_horizontal_50_ac4_av 0.13636363636363635\n",
      "prospect_horizontal_50_ac4_ev 0.22727272727272727\n",
      "prospect_horizontal_50_ac5_av 1.0\n",
      "prospect_horizontal_50_ec_ev 1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(new_dirs)):\n",
    "    print(new_dirs[i], acc_models['AOA_3_cross'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7a57537b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tpc\n",
      "Finished write data file\n"
     ]
    }
   ],
   "source": [
    "df_and_ground = get_data_and_ground('prospect_horizontal_0_ac2_av')\n",
    "data_name1= df_and_ground[0]\n",
    "data_name2= df_and_ground[1]\n",
    "df1 = df_and_ground[2]\n",
    "df2 = df_and_ground[3]\n",
    "ground_t1 = df_and_ground[4]\n",
    "    \n",
    "data_test1 = get_data(df1,df2,ground_t1, data_name1=data_name1,data_name2=data_name2)\n",
    "df_data_test1= pd.DataFrame(data_test1,columns = ['dataset1_name','dataset2_name', 'attr1_name', 'attr2_name', 'attribute_match', 'constraints'] )\n",
    "df_data_test1.to_pickle('test_{}.p'.format(all_data_name1))\n",
    "    \n",
    "testset1 = Dataset('test_{}.p'.format(all_data_name1), tokenizer,dat_fname='{0}_12_test.dat'.format(opt.dataset))\n",
    "    \n",
    "test_data_loader1 = DataLoader(dataset=testset1, batch_size=len(testset1), shuffle=False)\n",
    "    \n",
    "input_cols_1 = ['text_raw_indices1', 'aspect_indices1','text_raw_indices2', 'aspect_indices2', 'constraints']\n",
    "    \n",
    "res = _test_model(test_data_loader1, model_3, input_cols_1, data_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9fcf0268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AgencyID', 'AgeID'),\n",
       " ('LastName', 'LaN'),\n",
       " ('FirstName', 'FiN'),\n",
       " ('MiddleInitial', 'MidInit'),\n",
       " ('Gender', 'Ge'),\n",
       " ('AddressLine1', 'AdL1'),\n",
       " ('AddressLine2', 'AdLi2'),\n",
       " ('PostalCode', 'PosC'),\n",
       " ('City', 'Ci'),\n",
       " ('State', 'Sta'),\n",
       " ('Country', 'Coun'),\n",
       " ('Phone', 'Ph'),\n",
       " ('Income', 'Inc'),\n",
       " ('NumberCars', 'NumC'),\n",
       " ('NumberChildren', 'NuCh'),\n",
       " ('MaritalStatus', 'MariSta'),\n",
       " ('Age', 'Ag'),\n",
       " ('CreditRating', 'CrRat'),\n",
       " ('OwnOrRentFlag', 'OOReFl'),\n",
       " ('Employer', 'Em'),\n",
       " ('NumberCreditCards', 'NuCreCa'),\n",
       " ('NetWorth', 'NeWo')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ce23d734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9442148760330579,\n",
       " [(['AddressLine1', 'AdL1'], tensor([-0.4321,  0.4330])),\n",
       "  (['AddressLine2', 'AdLi2'], tensor([-1.3647,  1.3624])),\n",
       "  (['City', 'OOReFl'], tensor([-1.7710,  1.7691])),\n",
       "  (['Phone', 'LaN'], tensor([-0.1798,  0.1812])),\n",
       "  (['Phone', 'FiN'], tensor([-0.1798,  0.1812])),\n",
       "  (['Phone', 'MidInit'], tensor([-0.0269,  0.0278])),\n",
       "  (['Phone', 'Ph'], tensor([-2.2842,  2.2812])),\n",
       "  (['Phone', 'Inc'], tensor([-0.1466,  0.1479])),\n",
       "  (['Phone', 'NuCh'], tensor([-0.4969,  0.4960])),\n",
       "  (['Phone', 'Em'], tensor([-0.0508,  0.0519])),\n",
       "  (['Phone', 'NuCreCa'], tensor([-0.4916,  0.4907])),\n",
       "  (['MaritalStatus', 'MariSta'], tensor([-0.4891,  0.4900])),\n",
       "  (['Age', 'AgeID'], tensor([-0.1608,  0.1609]))])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "339c6d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.18181818181818182,\n",
       " {'AddressLine1': ('AdL1', tensor([-0.4321,  0.4330])),\n",
       "  'AddressLine2': ('AdLi2', tensor([-1.3647,  1.3624])),\n",
       "  'City': ('OOReFl', tensor([-1.7710,  1.7691])),\n",
       "  'Phone': ('Ph', tensor([-2.2842,  2.2812])),\n",
       "  'MaritalStatus': ('MariSta', tensor([-0.4891,  0.4900])),\n",
       "  'Age': ('AgeID', tensor([-0.1608,  0.1609]))})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = _test_on_ground_truth(ground_t1, res[1])\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6f2ae2",
   "metadata": {},
   "source": [
    "### А что если обучить на 3 датасетах?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ed929ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_data(names):\n",
    "    data=[]\n",
    "    for name in names:\n",
    "        df_and_ground = get_data_and_ground(name)\n",
    "\n",
    "        data_name1= df_and_ground[0]\n",
    "        data_name2= df_and_ground[1]\n",
    "        df1 = df_and_ground[2]\n",
    "        df2 = df_and_ground[3]\n",
    "        ground_t1 = df_and_ground[4]\n",
    "\n",
    "        data_train = get_data(df1,df2,ground_t1, data_name1=data_name1,data_name2=data_name2)\n",
    "        data+=data_train\n",
    "    df_data= pd.DataFrame(data,columns = ['dataset1_name','dataset2_name', 'attr1_name', 'attr2_name', 'attribute_match', 'constraints'] )\n",
    "    df_data.to_pickle('./datasets/omap/train_tpc.p')\n",
    "names = ['prospect_horizontal_50_ec_ev','prospect_horizontal_50_ac2_ev','prospect_horizontal_50_ac5_av']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb24e3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_train_data(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f788d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b2aa7e7",
   "metadata": {},
   "source": [
    "Обучаем модель\n",
    "\n",
    "python train_2.py --dataset tpc_2 --model_name aoa_3\n",
    "\n",
    "state_dict_2/tpc_2/aoa_3_tpc_2_val_f1_0.9755"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8b32f6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading tokenizer: tpc_2_tokenizer.dat\n",
      "loading embedding_matrix: 300_tpc_2_embedding_matrix.dat\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n",
      "tpc\n",
      "Finished write data file\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pth = r'C:\\Users\\shepe\\Downloads\\Valentine-datasets\\prospect\\Unionable'\n",
    "dirs = os.listdir(pth)\n",
    "\n",
    "class opt(object):\n",
    "    def __init__(self):\n",
    "        self.max_seq_len = 240\n",
    "        self.dataset = 'tpc_2'\n",
    "        self.embed_dim = 300\n",
    "        self.hidden_dim = 300\n",
    "        self.class_dim = 2\n",
    "        self.constr_dim = 28\n",
    "opt = opt()\n",
    "fnames = ['./datasets/omap/train_tpc.p']\n",
    "\n",
    "tokenizer = build_tokenizer(\n",
    "    fnames,\n",
    "    max_seq_len=opt.max_seq_len,\n",
    "    dat_fname='{0}_tokenizer.dat'.format(opt.dataset))\n",
    "embedding_matrix = build_embedding_matrix(\n",
    "    word2idx=tokenizer.word2idx,\n",
    "    embed_dim=opt.embed_dim,\n",
    "    dat_fname='{0}_{1}_embedding_matrix.dat'.format(str(opt.embed_dim), opt.dataset))\n",
    "\n",
    "model_1 = AOA_3(embedding_matrix ,opt)\n",
    "model_1.load_state_dict(state_dict = torch.load('state_dict_2/tpc_2/aoa_3_tpc_2_val_f1_0.9755'))#10 эпох\n",
    "model_1.eval()\n",
    "\n",
    "model_2 = AOA_3(embedding_matrix ,opt)\n",
    "model_2.load_state_dict(state_dict = torch.load('state_dict_2/tpc_2/aoa_3_tpc_2_val_f1_0.9762'))#10+ эпох\n",
    "model_2.eval()\n",
    "\n",
    "acc_models = {'AOA_3_cross':[], 'AOA_3_cross_2':[],'COMA':[], 'Cupid':[], 'DistributionBased':[]}\n",
    "\n",
    "for dir_ in dirs:\n",
    "    matcher_1 = Coma(strategy=\"COMA_OPT\")\n",
    "    matcher_2 = Cupid()\n",
    "    matcher_3 = DistributionBased()\n",
    "    if dir_ not in names:\n",
    "        data = get_data_and_ground(dir_)\n",
    "        \n",
    "        acc1 = test_dl_models(data, model_1)\n",
    "        acc2 = test_dl_models(data, model_2)\n",
    "        acc3 = test_valentine_models(data, matcher_1)\n",
    "        acc4 = test_valentine_models(data, matcher_2)\n",
    "        acc5 = test_valentine_models(data, matcher_3)\n",
    "        \n",
    "        acc_models['AOA_3_cross'] = acc_models['AOA_3_cross']+[acc1[0]]\n",
    "        acc_models['AOA_3_cross_2'] = acc_models['AOA_3_cross_2']+[acc2[0]]\n",
    "        acc_models['COMA'] = acc_models['COMA']+[acc3[0]]\n",
    "        acc_models['Cupid'] = acc_models['Cupid']+[acc4[0]]\n",
    "        acc_models['DistributionBased'] = acc_models['DistributionBased']+[acc5[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cbab6ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8402203856749311"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_models['AOA_3_cross'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "84eb0ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_models['AOA_3_cross_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6d5ceb2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.778236914600551"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_models['COMA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c7beafb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5840220385674931"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_models['Cupid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "284b1629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7782369146005509"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_models['DistributionBased'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
