{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75a923c7",
   "metadata": {},
   "source": [
    "Тестируем полученные модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078c670e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from valentine import valentine_match, valentine_metrics\n",
    "from valentine.algorithms import Coma, Cupid, DistributionBased\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from time import strftime, localtime\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,TensorDataset,random_split,SubsetRandomSampler, ConcatDataset\n",
    "from torchview import draw_graph\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from data_utils_2 import build_tokenizer, build_embedding_matrix, Dataset\n",
    "\n",
    "from models import AOA, AOA_2, AOA_3, AOA_4 , AOA_5, AOA_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bd8560",
   "metadata": {},
   "outputs": [],
   "source": [
    "from create_datasets import get_data, get_data_f,get_data_2, get_data_and_ground\n",
    "\n",
    "with open('names.p', 'rb') as file:\n",
    "    names = pickle.load(file)\n",
    "\n",
    "def _test_model(data_loader, m, inputs_cols, data_test):\n",
    "    with torch.no_grad():\n",
    "        for t_batch, t_sample_batched in enumerate(data_loader):\n",
    "            t_inputs = [t_sample_batched[col] for col in inputs_cols]\n",
    "            t_targets = t_sample_batched['class_n']\n",
    "            t_outputs = m(t_inputs)\n",
    "            res = []\n",
    "            for i in range(len(t_targets)):\n",
    "                if torch.argmax(t_outputs[i], -1)==1:\n",
    "                    res.append((data_test[i][2:4],t_outputs[i]))\n",
    "                    \n",
    "\n",
    "            n_correct = (torch.argmax(t_outputs, -1) == t_targets).sum().item()\n",
    "            n_total = len(t_outputs)\n",
    "\n",
    "    acc = n_correct / n_total\n",
    "    return acc, res\n",
    "\n",
    "def _test_on_ground_truth(ground_tr, predicted):\n",
    "    answer = {}\n",
    "    \n",
    "    predicted_unique = {i[0][1]:0 for i in predicted}\n",
    "    \n",
    "    for truth in ground_tr:\n",
    "        chosen_pr=''\n",
    "        for pr in predicted:\n",
    "            if truth[0]==pr[0][0] and  predicted_unique[pr[0][1]]<1:\n",
    "                if type(answer.get(truth[0], 0)) ==int: \n",
    "                    answer[truth[0]] = (pr[0][1], pr[1])\n",
    "                    chosen_pr=pr[0][1]\n",
    "                else:\n",
    "                    prob_1 = nn.functional.softmax(answer[truth[0]][1], dim=0)\n",
    "                    prob_2 = nn.functional.softmax(pr[1], dim=0)\n",
    "                    if prob_1[1]<prob_2[1]:\n",
    "                        answer[truth[0]] = (pr[0][1], pr[1])\n",
    "                        chosen_pr=pr[0][1]\n",
    "        predicted_unique[chosen_pr]=predicted_unique.get(chosen_pr,0)+1\n",
    "    total_tr = 0\n",
    "    for i in ground_tr:\n",
    "        try:\n",
    "            if i == (i[0], answer[i[0]][0]):\n",
    "                total_tr+=1\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return total_tr/len(ground_tr), answer\n",
    "                    \n",
    "\n",
    "def test_dl_models(df_and_ground, model):\n",
    "    data_name1= df_and_ground[0]\n",
    "    data_name2= df_and_ground[1]\n",
    "    df1 = df_and_ground[2]\n",
    "    df2 = df_and_ground[3]\n",
    "    ground_t1 = df_and_ground[4]\n",
    "    \n",
    "    name = data_name1 +'_'+ data_name2\n",
    "    \n",
    "    data_test1 = get_data(df1,df2,ground_t1, data_name1=data_name1,data_name2=data_name2)\n",
    "    df_data_test1= pd.DataFrame(data_test1,columns = ['dataset1_name','dataset2_name', 'attr1_name', 'attr2_name', 'attribute_match', 'constraints'] )\n",
    "    df_data_test1.to_pickle('test_{}.p'.format(name))\n",
    "    \n",
    "    testset1 = Dataset('test_{}.p'.format(name), tokenizer,dat_fname='{0}_12_test.dat'.format(opt.dataset))\n",
    "    \n",
    "    test_data_loader1 = DataLoader(dataset=testset1, batch_size=len(testset1), shuffle=False)\n",
    "    \n",
    "    input_cols_1 = ['text_raw_indices1', 'aspect_indices1','text_raw_indices2', 'aspect_indices2', 'constraints']\n",
    "    \n",
    "    res = _test_model(test_data_loader1, model, input_cols_1, data_test1)\n",
    "    \n",
    "    acc = _test_on_ground_truth(ground_t1, res[1])\n",
    "        \n",
    "    return acc\n",
    "\n",
    "def _test_on_ground_truth_valentine(ground_tr, predicted):\n",
    "    i=0\n",
    "    total_tr = 0\n",
    "    for it in predicted.items():\n",
    "        for gr in ground_tr:\n",
    "            if gr == (it[0][0][1], it[0][1][1]):\n",
    "                total_tr+=1\n",
    "        i+=1\n",
    "    return total_tr/len(ground_tr)\n",
    "\n",
    "def test_valentine_models(df_and_ground, matcher):\n",
    "    data_name1= df_and_ground[0]\n",
    "    data_name2= df_and_ground[1]\n",
    "    df1 = df_and_ground[2]\n",
    "    df2 = df_and_ground[3]\n",
    "    ground_t = df_and_ground[4]\n",
    "    \n",
    "    matches = valentine_match(df1, df2, matcher)\n",
    "    return _test_on_ground_truth_valentine(ground_t, matches), matches\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f9f912",
   "metadata": {},
   "outputs": [],
   "source": [
    "pth = r'C:\\Users\\shepe\\Downloads\\Valentine-datasets\\prospect\\Unionable'\n",
    "dirs = os.listdir(pth)\n",
    "\n",
    "class opt(object):\n",
    "    def __init__(self):\n",
    "        self.max_seq_len = 240\n",
    "        self.dataset = 'tpc_3'\n",
    "        self.embed_dim = 300\n",
    "        self.hidden_dim = 300\n",
    "        self.class_dim = 2\n",
    "        self.constr_dim = 28\n",
    "opt = opt()\n",
    "\n",
    "with open('pathes.p', 'rb') as file:\n",
    "    pathes = pickle.load(file)\n",
    "pathes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86463809",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_acc = []\n",
    "for i in range(1,17):\n",
    "    number = str(i)\n",
    "    fnames = ['./datasets/omap/train_tpc{}.p'.format(number)]\n",
    "\n",
    "    tokenizer = build_tokenizer(\n",
    "        fnames,\n",
    "        max_seq_len=opt.max_seq_len,\n",
    "        dat_fname='{0}_{1}_tokenizer.dat'.format(opt.dataset, number))\n",
    "    embedding_matrix = build_embedding_matrix(\n",
    "        word2idx=tokenizer.word2idx,\n",
    "        embed_dim=opt.embed_dim,\n",
    "        dat_fname='{0}_{1}_{2}_embedding_matrix.dat'.format(str(opt.embed_dim), opt.dataset, number))\n",
    "\n",
    "    model_1 = AOA_4(embedding_matrix ,opt)\n",
    "    model_1.load_state_dict(state_dict = torch.load(pathes[i-1]))\n",
    "    model_1.eval()\n",
    "\n",
    "\n",
    "    acc_models = {'AOA_4':[], 'COMA':[]}\n",
    "\n",
    "    for dir_ in dirs:\n",
    "        matcher_1 = Coma(strategy=\"COMA_OPT\")\n",
    "        if dir_ not in names[:i+1]:\n",
    "            data = get_data_and_ground(dir_)\n",
    "\n",
    "            acc1 = test_dl_models(data, model_1)\n",
    "            acc2 = test_valentine_models(data, matcher_1)\n",
    "\n",
    "            acc_models['AOA_4'] = acc_models['AOA_4']+[acc1[0]]\n",
    "            acc_models['COMA'] = acc_models['COMA']+[acc2[0]]\n",
    "            \n",
    "    all_acc.append(acc_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5453b2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in all_acc:\n",
    "    print(np.mean(i['AOA_4']), np.mean(i['COMA']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f642af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('accuracy.p', 'wb') as file:\n",
    "    pickle.dump(all_acc, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d11a585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d927b87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "y1 = [np.mean(i['AOA_4']) for i in all_acc]\n",
    "y2 = [np.mean(i['COMA']) for i in all_acc]\n",
    "x = list(range(2,12))\n",
    "plt.plot(x, y1[:10])\n",
    "plt.plot(x, y2[:10])\n",
    "plt.legend(['DL model','COMA'])\n",
    "ax = plt.subplot()\n",
    "ax.set_xlabel('количество обучающих данных')\n",
    "ax.set_ylabel('точность моделей (accuracy)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fb9bc5",
   "metadata": {},
   "source": [
    "с 1 ограничением"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b27cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dl_models_c1(df_and_ground, model):\n",
    "    data_name1= df_and_ground[0]\n",
    "    data_name2= df_and_ground[1]\n",
    "    df1 = df_and_ground[2]\n",
    "    df2 = df_and_ground[3]\n",
    "    ground_t1 = df_and_ground[4]\n",
    "    \n",
    "    name = data_name1 +'_'+ data_name2\n",
    "    \n",
    "    data_test1 = get_data_2(df1,df2,ground_t1, data_name1=data_name1,data_name2=data_name2)\n",
    "    df_data_test1= pd.DataFrame(data_test1,columns = ['dataset1_name','dataset2_name', 'attr1_name', 'attr2_name', 'attribute_match', 'constraints'] )\n",
    "    df_data_test1.to_pickle('test_{}.p'.format(name))\n",
    "    \n",
    "    testset1 = Dataset('test_{}.p'.format(name), tokenizer,dat_fname='{0}_12_test.dat'.format(opt.dataset))\n",
    "    \n",
    "    test_data_loader1 = DataLoader(dataset=testset1, batch_size=len(testset1), shuffle=False)\n",
    "    \n",
    "    input_cols_1 = ['text_raw_indices1', 'aspect_indices1','text_raw_indices2', 'aspect_indices2', 'constraints']\n",
    "    \n",
    "    res = _test_model(test_data_loader1, model, input_cols_1, data_test1)\n",
    "    \n",
    "    acc = _test_on_ground_truth(ground_t1, res[1])\n",
    "        \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf9b5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pathes_with_1_constraint.p', 'rb') as file:\n",
    "    pathes_c1 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f463e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pth = r'C:\\Users\\shepe\\Downloads\\Valentine-datasets\\prospect\\Unionable'\n",
    "dirs = os.listdir(pth)\n",
    "class opt(object):\n",
    "    def __init__(self):\n",
    "        self.max_seq_len = 240\n",
    "        self.dataset = 'tpc_c1'\n",
    "        self.embed_dim = 300\n",
    "        self.hidden_dim = 300\n",
    "        self.class_dim = 2\n",
    "        self.constr_dim = 2\n",
    "opt = opt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b573d8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_acc = []\n",
    "for i in range(1,17):\n",
    "    number = str(i)\n",
    "    fnames = ['./datasets/with_1_constraint/train_tpc{}.p'.format(number)]\n",
    "\n",
    "    tokenizer = build_tokenizer(\n",
    "        fnames,\n",
    "        max_seq_len=opt.max_seq_len,\n",
    "        dat_fname='{0}_{1}_tokenizer.dat'.format(opt.dataset, number))\n",
    "    embedding_matrix = build_embedding_matrix(\n",
    "        word2idx=tokenizer.word2idx,\n",
    "        embed_dim=opt.embed_dim,\n",
    "        dat_fname='{0}_{1}_{2}_embedding_matrix.dat'.format(str(opt.embed_dim), opt.dataset, number))\n",
    "\n",
    "    model_1 = AOA_6(embedding_matrix ,opt)\n",
    "    model_1.load_state_dict(state_dict = torch.load(pathes_c1[i-1]))\n",
    "    model_1.eval()\n",
    "\n",
    "\n",
    "    acc_models = {'AOA_6':[]}\n",
    "\n",
    "    for dir_ in dirs:\n",
    "        matcher_1 = Coma(strategy=\"COMA_OPT\")\n",
    "        if dir_ not in names[:i+1]:\n",
    "            data = get_data_and_ground(dir_)\n",
    "\n",
    "            acc1 = test_dl_models_c1(data, model_1)\n",
    "\n",
    "            acc_models['AOA_6'] = acc_models['AOA_6']+[acc1[0]]\n",
    "            \n",
    "    all_acc.append(acc_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1915954",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('accuracy_c1.p', 'wb') as file:\n",
    "    pickle.dump(all_acc, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ba5be7",
   "metadata": {},
   "source": [
    "instance-based+schema-based+тэги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fa1199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _test_on_ground_truth_f(ground_tr, predicted):\n",
    "    predicted = [([pr[0][0].split('#')[0],pr[0][1].split('#')[0]],pr[1]) for pr in predicted]\n",
    "    answer = {}\n",
    "    predicted_unique = {i[0][1]:0 for i in predicted}\n",
    "    \n",
    "    for truth in ground_tr:\n",
    "        chosen_pr=''\n",
    "        for pr in predicted:\n",
    "            if truth[0]==pr[0][0] and  predicted_unique[pr[0][1]]<1:\n",
    "                if type(answer.get(truth[0], 0)) ==int: \n",
    "                    answer[truth[0]] = (pr[0][1], pr[1])\n",
    "                    chosen_pr=pr[0][1]\n",
    "                else:\n",
    "                    prob_1 = nn.functional.softmax(answer[truth[0]][1], dim=0)\n",
    "                    prob_2 = nn.functional.softmax(pr[1], dim=0)\n",
    "                    if prob_1[1]<prob_2[1]:\n",
    "                        answer[truth[0]] = (pr[0][1], pr[1])\n",
    "                        chosen_pr=pr[0][1]\n",
    "        predicted_unique[chosen_pr]=predicted_unique.get(chosen_pr,0)+1\n",
    "    total_tr = 0\n",
    "    for i in ground_tr:\n",
    "        try:\n",
    "            if i == (i[0], answer[i[0]][0]):\n",
    "                total_tr+=1\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return total_tr/len(ground_tr), answer\n",
    "                    \n",
    "\n",
    "def test_dl_models_f(df_and_ground, model,hxl_tags):\n",
    "    data_name1= df_and_ground[0]\n",
    "    data_name2= df_and_ground[1]\n",
    "    df1 = df_and_ground[2]\n",
    "    df2 = df_and_ground[3]\n",
    "    ground_t1 = df_and_ground[4]\n",
    "    \n",
    "    name = data_name1 +'_'+ data_name2\n",
    "    \n",
    "    data_test1 = get_data_f(df1,df2,ground_t1,hxl_tags, data_name1=data_name1,data_name2=data_name2)\n",
    "    df_data_test1= pd.DataFrame(data_test1,columns = ['dataset1_name','dataset2_name', 'attr1_name', 'attr2_name', 'attribute_match', 'constraints'] )\n",
    "    df_data_test1.to_pickle('test_{}.p'.format(name))\n",
    "    \n",
    "    testset1 = Dataset('test_{}.p'.format(name), tokenizer,dat_fname='{0}_1_test.dat'.format(opt.dataset))\n",
    "    \n",
    "    test_data_loader1 = DataLoader(dataset=testset1, batch_size=len(testset1), shuffle=False)\n",
    "    \n",
    "    input_cols_1 = ['text_raw_indices1', 'aspect_indices1','text_raw_indices2', 'aspect_indices2', 'constraints']\n",
    "    \n",
    "    res = _test_model(test_data_loader1, model, input_cols_1, data_test1)\n",
    "    acc = _test_on_ground_truth_f(ground_t1, res[1])\n",
    "        \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9716b22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pathes_with_feature_extraction.p', 'rb') as file:\n",
    "    pathes_f = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafbd3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pth = r'C:\\Users\\shepe\\Downloads\\Valentine-datasets\\prospect\\Unionable'\n",
    "dirs = os.listdir(pth)\n",
    "class opt(object):\n",
    "    def __init__(self):\n",
    "        self.max_seq_len = 240\n",
    "        self.dataset = 'tpc_f'\n",
    "        self.embed_dim = 300\n",
    "        self.hidden_dim = 300\n",
    "        self.class_dim = 2\n",
    "        self.constr_dim = 30\n",
    "opt = opt()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c8b7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hxl_tag import HXLTagger\n",
    "hxl_tagger = HXLTagger()\n",
    "hxl_tags = []\n",
    "for dir_1 in dirs:\n",
    "    if dir_1 not in names[:i+1]:\n",
    "        dfs = get_data_and_ground(dir_1)\n",
    "        df1 = dfs[2]\n",
    "        df2 = dfs[3]\n",
    "        t1 = hxl_tagger.get_hxl_tags(df1)\n",
    "        t2 = hxl_tagger.get_hxl_tags(df2)\n",
    "        hxl_tags.append([t1,t2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d276e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hxl_tags_test.p', 'wb') as file:\n",
    "    pickle.dump(hxl_tags, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b756ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hxl_tags_test.p', 'rb') as file:\n",
    "    hxl_tags = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10d6b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_acc = []\n",
    "for i in range(1,17):\n",
    "    number = str(i)\n",
    "    fnames = ['./datasets/with_feature_extraction/train_tpc{}.p'.format(number)]\n",
    "\n",
    "    tokenizer = build_tokenizer(\n",
    "        fnames,\n",
    "        max_seq_len=opt.max_seq_len,\n",
    "        dat_fname='{0}_{1}_tokenizer.dat'.format(opt.dataset, number))\n",
    "    embedding_matrix = build_embedding_matrix(\n",
    "        word2idx=tokenizer.word2idx,\n",
    "        embed_dim=opt.embed_dim,\n",
    "        dat_fname='{0}_{1}_{2}_embedding_matrix.dat'.format(str(opt.embed_dim), opt.dataset, number))\n",
    "\n",
    "    model_1 = AOA_6(embedding_matrix ,opt)\n",
    "    model_1.load_state_dict(state_dict = torch.load(pathes_f[i-1]))\n",
    "    model_1.eval()\n",
    "\n",
    "\n",
    "    acc_models = {'AOA_6_f':[]}\n",
    "    \n",
    "\n",
    "    j=0\n",
    "    for dir_ in dirs:\n",
    "        if dir_ not in names[:i+1]:\n",
    "            data = get_data_and_ground(dir_)\n",
    "\n",
    "            acc1 = test_dl_models_f(data, model_1, hxl_tags[j])\n",
    "\n",
    "            acc_models['AOA_6_f'] = acc_models['AOA_6_f']+[acc1[0]]\n",
    "            j+=1\n",
    "            \n",
    "    all_acc.append(acc_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82807b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('accuracy_f.p', 'wb') as file:\n",
    "    pickle.dump(all_acc, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faac7687",
   "metadata": {},
   "source": [
    "Федеративное обучение с 1 ограничением"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229827d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5ed664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameters(net, state_dict):\n",
    "    parameters = [val.cpu().numpy() for _, val in state_dict.items()]\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2292dfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pth = r'C:\\Users\\shepe\\Downloads\\Valentine-datasets\\prospect\\Unionable'\n",
    "dirs = os.listdir(pth)\n",
    "class opt(object):\n",
    "    def __init__(self):\n",
    "        self.max_seq_len = 240\n",
    "        self.dataset = 'tpc_c1'\n",
    "        self.embed_dim = 300\n",
    "        self.hidden_dim = 300\n",
    "        self.class_dim = 2\n",
    "        self.constr_dim = 2\n",
    "opt = opt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64116a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_acc = []\n",
    "for i in range(1,17):\n",
    "    print(\"Iteration: \", i)\n",
    "    number = str(i)\n",
    "    fnames = ['./datasets/with_1_constraint/train_tpc{}.p'.format(number)]\n",
    "\n",
    "    tokenizer = build_tokenizer(\n",
    "        fnames,\n",
    "        max_seq_len=opt.max_seq_len,\n",
    "        dat_fname='{0}_{1}_tokenizer.dat'.format(opt.dataset, number))\n",
    "    embedding_matrix = build_embedding_matrix(\n",
    "        word2idx=tokenizer.word2idx,\n",
    "        embed_dim=opt.embed_dim,\n",
    "        dat_fname='{0}_{1}_{2}_embedding_matrix.dat'.format(str(opt.embed_dim), opt.dataset, number))\n",
    "\n",
    "    model_1 = AOA_6(embedding_matrix ,opt)\n",
    "    for j in range(1,11):\n",
    "        model_1.load_state_dict(state_dict = torch.load(f\"state_dict_2/tpc_c1/model_{i}_round_{j}.pth\"))\n",
    "        model_1.eval()\n",
    "\n",
    "\n",
    "        acc_models_fed = {f'AOA_6_{j}':[]}\n",
    "\n",
    "        for dir_ in dirs:\n",
    "            matcher_1 = Coma(strategy=\"COMA_OPT\")\n",
    "            if dir_ not in names[:i+1]:\n",
    "                data = get_data_and_ground(dir_)\n",
    "\n",
    "                acc1 = test_dl_models_c1(data, model_1)\n",
    "\n",
    "                acc_models_fed[f'AOA_6_{j}'] = acc_models_fed[f'AOA_6_{j}']+[acc1[0]]\n",
    "\n",
    "        all_acc.append(acc_models_fed)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265426d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('accuracy_fed_c1.p', 'wb') as file:\n",
    "    pickle.dump(all_acc, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164eec54",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('accuracy_fed_c1.p', 'rb') as file:\n",
    "    all_acc = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb87c5d",
   "metadata": {},
   "source": [
    "Федеративное обучение instance-based+schema-based+тэги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da248bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hxl_tags_test.p', 'rb') as file:\n",
    "    hxl_tags = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e384b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pth = r'C:\\Users\\shepe\\Downloads\\Valentine-datasets\\prospect\\Unionable'\n",
    "dirs = os.listdir(pth)\n",
    "class opt(object):\n",
    "    def __init__(self):\n",
    "        self.max_seq_len = 240\n",
    "        self.dataset = 'tpc_f'\n",
    "        self.embed_dim = 300\n",
    "        self.hidden_dim = 300\n",
    "        self.class_dim = 2\n",
    "        self.constr_dim = 30\n",
    "opt = opt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe78def7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_acc = []\n",
    "for i in range(1,17):\n",
    "    print(\"Iteration: \", i)\n",
    "    number = str(i)\n",
    "    fnames = ['./datasets/with_feature_extraction/train_tpc{}.p'.format(number)]\n",
    "\n",
    "    tokenizer = build_tokenizer(\n",
    "        fnames,\n",
    "        max_seq_len=opt.max_seq_len,\n",
    "        dat_fname='{0}_{1}_tokenizer.dat'.format(opt.dataset, number))\n",
    "    embedding_matrix = build_embedding_matrix(\n",
    "        word2idx=tokenizer.word2idx,\n",
    "        embed_dim=opt.embed_dim,\n",
    "        dat_fname='{0}_{1}_{2}_embedding_matrix.dat'.format(str(opt.embed_dim), opt.dataset, number))\n",
    "\n",
    "    model_1 = AOA_6(embedding_matrix ,opt)\n",
    "    for j in range(1,11):\n",
    "        model_1.load_state_dict(state_dict = torch.load(f\"state_dict_2/tpc_f/model_{i}_round_{j}.pth\"))\n",
    "        model_1.eval()\n",
    "\n",
    "\n",
    "        acc_models_fed = {f'AOA_6_{j}':[]}\n",
    "        ind=0\n",
    "        for dir_ in dirs:\n",
    "            if dir_ not in names[:i+1]:\n",
    "                data = get_data_and_ground(dir_)\n",
    "\n",
    "                acc1 = test_dl_models_f(data, model_1, hxl_tags[ind])\n",
    "                ind+=1\n",
    "\n",
    "                acc_models_fed[f'AOA_6_{j}'] = acc_models_fed[f'AOA_6_{j}']+[acc1[0]]\n",
    "\n",
    "        all_acc.append(acc_models_fed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4baf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('accuracy_fed_f.p', 'wb') as file:\n",
    "    pickle.dump(all_acc, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d055cb0e",
   "metadata": {},
   "source": [
    "Федеративное обучение instance-based+schema-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc49a84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pth = r'C:\\Users\\shepe\\Downloads\\Valentine-datasets\\prospect\\Unionable'\n",
    "dirs = os.listdir(pth)\n",
    "class opt(object):\n",
    "    def __init__(self):\n",
    "        self.max_seq_len = 240\n",
    "        self.dataset = 'tpc_3'\n",
    "        self.embed_dim = 300\n",
    "        self.hidden_dim = 300\n",
    "        self.class_dim = 2\n",
    "        self.constr_dim = 28\n",
    "opt = opt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5137f19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_acc = []\n",
    "for i in range(1,17):\n",
    "    print(\"Iteration: \", i)\n",
    "    number = str(i)\n",
    "    fnames = ['./datasets/omap/train_tpc{}.p'.format(number)]\n",
    "\n",
    "    tokenizer = build_tokenizer(\n",
    "        fnames,\n",
    "        max_seq_len=opt.max_seq_len,\n",
    "        dat_fname='{0}_{1}_tokenizer.dat'.format(opt.dataset, number))\n",
    "    embedding_matrix = build_embedding_matrix(\n",
    "        word2idx=tokenizer.word2idx,\n",
    "        embed_dim=opt.embed_dim,\n",
    "        dat_fname='{0}_{1}_{2}_embedding_matrix.dat'.format(str(opt.embed_dim), opt.dataset, number))\n",
    "\n",
    "    model_1 = AOA_5(embedding_matrix ,opt)\n",
    "    for j in range(1,11):\n",
    "        model_1.load_state_dict(state_dict = torch.load(f\"state_dict_2/tpc_2/model_{i}_round_{j}.pth\"))\n",
    "        model_1.eval()\n",
    "\n",
    "\n",
    "        acc_models_fed = {f'AOA_5_{j}':[]}\n",
    "\n",
    "        for dir_ in dirs:\n",
    "            matcher_1 = Coma(strategy=\"COMA_OPT\")\n",
    "            if dir_ not in names[:i+1]:\n",
    "                data = get_data_and_ground(dir_)\n",
    "\n",
    "                acc1 = test_dl_models(data, model_1)\n",
    "\n",
    "                acc_models_fed[f'AOA_5_{j}'] = acc_models_fed[f'AOA_5_{j}']+[acc1[0]]\n",
    "\n",
    "        all_acc.append(acc_models_fed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5c8caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('accuracy_fed.p', 'wb') as file:\n",
    "    pickle.dump(all_acc, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885580c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('accuracy_fed.p', 'rb') as file:\n",
    "    fed_acc = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702bf144",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('accuracy.p', 'rb') as file:\n",
    "    all_acc_1 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41035d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_acc = []\n",
    "i = 0\n",
    "for acc in fed_acc:\n",
    "    mean_acc.append(np.mean(acc[f'AOA_5_{i % 10 + 1}']))\n",
    "    i+=1\n",
    "print(len(mean_acc))\n",
    "max_acc = []\n",
    "for j in range(0,len(mean_acc)-9, 10):\n",
    "    max_acc.append(max(mean_acc[j:j+10]))\n",
    "max_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a55ebff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "y1 = [np.mean(i['AOA_4']) for i in all_acc_1]\n",
    "y2 = [np.mean(i['COMA']) for i in all_acc_1]\n",
    "y3 = max_acc\n",
    "x = list(range(2,17))\n",
    "plt.plot(x, y1[:15])\n",
    "plt.plot(x, y2[:15])\n",
    "plt.plot(x, y3[:15])\n",
    "plt.legend(['DL model','COMA','FED'])\n",
    "ax = plt.subplot()\n",
    "ax.set_xlabel('количество обучающих данных')\n",
    "ax.set_ylabel('точность моделей (accuracy)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fba920d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
